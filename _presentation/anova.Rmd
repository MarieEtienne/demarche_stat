---
title: Analyse de la variance
subtitle: à 1 facteur
author: Marie-Pierre Etienne
date: '2020/09/11 (updated: `r Sys.Date()`)'
institute: https://github.com/marieetienne
csl: ../courses_tools/resources/apa-no-doi-no-issue.csl
output:
  xaringan::moon_reader:
    css: [  'metropolis',  'mpe_pres.css']
    lib_dir: libs
    nature:
      ratio: 16:10
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: '../courses_tools/resources/collapseoutput.js'
    includes:
      after_body: '../courses_tools/resources/insert-logo.html'
fontsize: 10pt
params:
  child_path: ''
  setup_path: ../courses_tools/resources/
---



```{r setup, include=FALSE, eval = TRUE}
source(paste0(params$setup_path, "knitr_setup.R"))
with_sol <- TRUE ## in order to control the output
with_course <- TRUE
library('flipbookr')
library(RefManageR)
library(tidyverse)
library(ggplot2)
```

```{r xaringanExtra-share-again, echo=FALSE}
xaringanExtra::use_share_again()
```

```{r reference,  include=FALSE, cache=FALSE, eval = TRUE}
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "alphabetic",
           style = "markdown",
           hyperlink = FALSE,
           dashed = FALSE)
myBib <- ReadBib("./lm.bib", check = FALSE)
```

name: intro
# Introduction

---
template: intro
## Un exemple jouet à but pédagogique

On a mesuré la fréquence cardiaque de 12 femmes et 12 hommes qui pratique des activités sportives différentes (Natation, Pilate, Pétanque).


```{r datapackage, eval = TRUE, echo = FALSE, warning = FALSE}
ggplot_save <- function(...) ggplot2::ggplot(...) 
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) 
#remotes::install_github('MarieEtienne/coursesdata', force = TRUE)
```

```{r freqdata, eval = TRUE, echo = c(1,2), warning = FALSE}
freqdata <- read.table('https://marieetienne.github.io/datasets/activite_FC.csv', sep = ",", header = TRUE )
freqdata %>% ggplot() +  aes(x= Activite, y = freqC) +  geom_boxplot( alpha = 0.5) + theme(legend.position = 'none')  + 
  geom_jitter(  alpha=0.7, width = 0.15)
```


--
<p class="question"> L'activité physique est-elle liée à  fréquence cardiaque au repos ?</p>

---
template: intro
## Cas d'étude Chauve souris

- Des espèces avec différents régimes alimentaires.
- L'écho localisation (capacité auditive) est un sens essentiel pour les insectivores.

`r Citet(myBib, "hutcheon2002comparative")` ont recensé pour 63 espèces de chauves souris l'espèce, le régime alimentaire, le clade (groupe dans l'arbre phylogénétique), différentes variables morphologiques dont le volume du cerveau dédié à l'audition (AUD)

```{r batsdata, eval = TRUE, echo = FALSE}
bats <- read.table('https://marieetienne.github.io/datasets/bats.csv', sep = ",", header = TRUE)
bats %>% ggplot() + aes(x= as.factor(Diet), y = AUD) +geom_boxplot(aes(col = as.factor(Diet), fill = as.factor(Diet)), alpha = 0.5) + 
  geom_jitter(size=0.8, alpha=0.7, width = 0.15, aes(col = as.factor(Diet))) + scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + theme(legend.position = 'none') + xlab('Diet')
```

--
<p class="question"> Le volume de la partie auditive du cerveau est il lié au régime alimentaire ?</p>

---
template: intro
## Cadre général du modèle d'analyse de la variance à 1 facteur
On étudie le lien entre  
- variable quantitative notée $Y$ (la fréquence cardiaque, volume de cerveau),
- et une variable qualitative (un facteur) pourvant prendre $I$ modalités (I=3 pour l'exemple 1 et I=4 dans l'exemple 2). 


Les données peuvent être visualisées à l'aide d'un boxplot.


--
<p class="question"> La variable d'intérêt Y  est-elle en moyenne différente selon les différentes modalités ?</p>



---
template: intro

## Graphiquement 

Une visalisation graphique du modèle d'analyse de la variance.

<br> <br> <br> <br>


Comment imagine-t-on le processus aléatoire qui a conduit à nos données ?


---

```{r anova_versiongraphique, eval = TRUE, echo = FALSE}
set.seed(321)
I <- 3
mu <- round(1.5 * rnorm(I),2)
effectif <- runif(n = I, min = 10, max = 30)
fake_dta <- tibble( groupe = rep(1:I, effectif)) %>% group_by(groupe) %>% 
  mutate(y = round(rnorm(n(), mean = mu[groupe], sd = 2),2), mean = mu[groupe] ) %>% mutate(groupe = as.factor(groupe), ord=0)  
norm_dta <- tibble( x  = seq( min(mu) -3*2, max(mu)+ 3* 2, length.out = 100))  %>% 
  mutate(d1 = dnorm(x, mean = mu[1], sd = 2),
         d2 = dnorm(x, mean = mu[2], sd = 2),
         d3 = dnorm(x, mean = mu[3], sd = 2)
  ) %>% 
  pivot_longer(cols = starts_with("d"), names_to = 'Groupe', values_to ='density' )%>% 
  mutate(groupe = as.factor(as.numeric(as.factor(Groupe))))
```

```{r anova_versiongraphique_proba}
ggplot() + 
  xlab('y') +
  ggtitle('Modèle M1') +
  geom_line(data = norm_dta, aes(x= x, y = density, col = groupe)) +
  scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +
  theme(legend.position = 'none') + 
  labs(col = 'Groupe') + #BREAK
  geom_vline(data=fake_dta, aes(xintercept = mean, col = groupe), alpha = 0.6) +#BREAK
  geom_point(data = fake_dta, aes(x = y, col = groupe, y=ord), size = 2, alpha = 0.7) 

```

`r chunk_reveal("anova_versiongraphique_proba", break_type = "user", display_type="output")`
---
count:false

```{r anova_versiongraphique_proba2, eval = TRUE, echo = FALSE}
ggplot() +  ggtitle('Modèle M1') +  
  xlab('y') +
  geom_point(data = fake_dta, aes(x = y, col = groupe, y=ord), size = 2, alpha = 0.7)  +
  scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +  theme(legend.position = 'none') +
  labs(col = 'Groupe') +
geom_line(data = norm_dta, aes(x= x, y = density, col = groupe), alpha= 0.1) +   
  geom_vline(data=fake_dta, aes(xintercept = mean, col = groupe), alpha = 0.1) #BREAK
```




```{r anova_versiongraphiqueM0, eval = TRUE, echo = FALSE}
mu0 <- mean(fake_dta$y)
fake_dta <- fake_dta %>% mutate(mu0 = mu0)
sd0 <- sd(fake_dta$y)
norm_dta_M0 <- tibble( x  = norm_dta$x)  %>% 
  mutate(d1 = dnorm(x, mean = mu0, sd = sd0),
         d2 = dnorm(x, mean = mu0, sd = sd0),
         d3 = dnorm(x, mean = mu0, sd = sd0)
  ) %>% 
  pivot_longer(cols = starts_with("d"), names_to = 'Groupe', values_to ='density' )%>% 
  mutate(groupe = as.factor(as.numeric(as.factor(Groupe))))
```

---

```{r anova_versiongraphique_proba_M0}
ggplot() + ggtitle('Modèle M0') + 
  xlab('y') +
  geom_line(data = norm_dta_M0, aes(x= x, y = density, col = groupe)) +  
  scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +
  theme(legend.position = 'none') + 
  labs(col = 'Groupe') + 
  geom_vline(data=fake_dta, aes(xintercept = mu0, col = groupe), alpha = 0.6) +#BREAK
  geom_point(data = fake_dta, aes(x = y, col = groupe, y=ord), size = 2, alpha = 0.7)
```

`r chunk_reveal("anova_versiongraphique_proba_M0", break_type = "user", display_type="output")`

---
count: false

```{r anova_versiongraphique_proba2_M0, eval = TRUE, echo = FALSE}
ggplot() +  
  xlab('y') +
  ggtitle('Modèle M0')  +  
  geom_point(data = fake_dta, aes(x = y, col = groupe, y=ord), size = 2, alpha = 0.7)  +
  scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +  
  theme(legend.position = 'none') + 
  labs(col = 'Groupe') + 
geom_line(data = norm_dta_M0, aes(x= x, y = density, col = groupe), alpha= 0.1) +  #BREAK
  geom_vline(data=fake_dta, aes(xintercept = mu0, col = groupe), alpha = 0.1) #BREAK
```

---
template: model
count: false

```{r anova_versiongraphique_save, eval = TRUE}
p_M1 <- ggplot() + 
  xlab('y') +
  ggtitle('Modèle M1') +
  geom_line(data = norm_dta, aes(x= x, y = density, col = groupe)) +
  scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +
  theme(legend.position = 'none') + 
  labs(col = 'Groupe') + #BREAK
  geom_vline(data=fake_dta, aes(xintercept = mean, col = groupe), alpha = 0.6) +#BREAK
  geom_point(data = fake_dta, aes(x = y, col = groupe, y=ord), size = 2, alpha = 0.7) 

p_M0 <-ggplot() +  
  xlab('y') +
  ggtitle('Modèle M0')  +  
  geom_point(data = fake_dta, aes(x = y, col = groupe, y=ord), size = 2, alpha = 0.7)  +
  scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) +  
  theme(legend.position = 'none') + 
  labs(col = 'Groupe') + 
geom_line(data = norm_dta_M0, aes(x= x, y = density, col = groupe), alpha= 0.1) +  
  geom_vline(data=fake_dta, aes(xintercept = mu0, col = groupe), alpha = 0.1) #BREAK
ggpubr::ggarrange(p_M1, p_M0, ncol = 2)
```


<p class="question"> Au vu de nos données, le modèle M1 est-il plus pertinent que le modèle M0 ?</p>


---
# Plan du cours

## Formaliser les modèles M0 et M1

## Estimer les paramètres inconnus

## Proposer une méthode pour décider entre M0 et M1

## Si M1, comparer les comportements moyens des groupes 2 à 2

---
name: model
# Formaliser les modèles M0 et M1

--

## Version régulière du modèle M1

$$\class{alea}{Y_{ik}} \overset{ind}{\sim}\mathcal{N}(\class{rouge}{\mu_i}, \class{rouge}{\sigma^2}),$$
avec 
- $i=1,\ldots,I$ le numéro du groupe,
- $k= 1,\ldots, n_i$ le numéro de l'individu dans le groupe $i$, 
- $n_i$ le nombre d'individus dans le groupe $i$ et $n=\sum_i n_i$ le nombre total d'individus,
- $\class{rouge}{\mu_i}$ le comportement moyen du groupe $i$,
- $\class{rouge}{\sigma^2}$ la variance commune à tous les groupes.

### Une écriture équivalente 

$$\class{alea}{Y_{ik}} = \class{rouge}{\mu_{i}} + \class{alea}{E_{ik}}, \quad \class{alea}{E_{ik}}\overset{ind}{\sim}\mathcal{N}(0, \class{rouge}{\sigma^2}).$$


### Nombre de paramètres du modèle

- $I$ paramètres de moyenne  $(\class{rouge}{\mu_1}, \class{rouge}{\mu_2}, \ldots, \class{rouge}{\mu_I})$; 
- 1 paramètre de variance $\class{rouge}{\sigma^2}$

---
template: model

## Version régulière du modèle M1 sur l'exemple 1

$$\class{alea}{Y_{ik}} \overset{ind}{\sim}\mathcal{N}(\class{rouge}{\mu_i}, \class{rouge}{\sigma^2}),$$
avec  $I=3$ et  la convention $i=1$ pour la natation et $i=2$ pour le pilate et $i=3$ pour la pétanque.

```{r freq_anova, eval= TRUE, echo = TRUE}
freqdata %>%group_by(Activite) %>% summarise(n= n())
```

- $k=1, \ldots, n_i$, avec $n_1=8$ et $n_2=8$ et $n_3=8$ et $n = 24$.
- $\class{rouge}{\mu_1}$ la fréquence cardiaque moyenne des nageurs/nageuses  et $\class{rouge}{\mu_2}$ des pratiquant.e.s de pilates et $\class{rouge}{\mu_3}$ celle des joueurs/joueuses de pétanque. 
- $\class{rouge}{\sigma^2}$ la variance commune à tous les groupes.

### Nombre de paramètres
- 3 paramètres de moyenne et  1 paramètre de variance

---
template: model
## Version singulière du modèle du modèle M1

$$\class{alea}{Y_{ik}} \overset{ind}{\sim}\mathcal{N}(\class{rouge}{\mu} + \class{rouge}{\alpha_i}, \class{rouge}{\sigma^2}),$$
avec 
- $i=1,\ldots,I$ le numéro du groupe,
- $k= 1,\ldots, n_i$ le numéro de l'individu dans le groupe $i$, ( $\sum_i n_i=n$ )
- $\class{rouge}{\mu}$ un comportement moyen de référence,
- $\class{rouge}{\alpha_i}$ un effet différentiel du groupe $i$par rapport à la référence,
- $\class{rouge}{\sigma^2}$ la variance commune à tous les groupes.

### Une écriture équivalente 

$$\class{alea}{Y_{ik}} = \class{rouge}{\mu} + \class{rouge}{\alpha_{i}} + \class{alea}{E_{ik}}, \quad \class{alea}{E_{ik}}\overset{ind}{\sim}\mathcal{N}(0, \class{rouge}{\sigma^2}).$$

### Nombre de paramètres du modèle

- $I+1$ paramètres de moyenne $(\mu, \alpha_1, \alpha_2, \ldots, \alpha_I)$,
- 1 paramètre de variance $\sigma^2.$

--

#### La version dans les logiciels et celle qui se généralise à plusieurs facteurs.

---
template: model
## Version singulière du modèle du modèle M1 sur l'exemple 1

$$\class{alea}{Y_{ik}} \overset{ind}{\sim}\mathcal{N}(\class{rouge}{\mu} + \class{rouge}{\alpha_i}, \class{rouge}{\sigma^2}),$$
avec 
- $I=3$ et  la convention $i=1$ pour la natation et $i=2$ pour le pilate et $i=3$ pour la pétanque.
- $k=1, \ldots, n_i$, avec $n_1=8,$  $n_2=8$ et $n_3=8$, 
- $\class{rouge}{\mu}$ la fréquence cardiaque moyenne de référence <a class="care"> Référence à définir </a> 
- $\class{rouge}{\alpha_1}$, l'effet différentiel de la pratique de la natation  par rapport à la référence, $\class{rouge}{\alpha_2}$ l'effet différentiel de la pratique du pilate et $\class{rouge}{\alpha_3}$ l'effet différentiel de la pratique de la pétanque  par rapport à la référence.
- $\class{rouge}{\sigma^2}$ la variance commune à tous les groupes.



### Nombre de paramètres
- 4 paramètres de moyenne
- 1 paramètre de variance


---
template: model
## Lien entre les deux versions du même modèle

 <table style="width:100%">
  <tr>
    <th>Groupe</th>
    <th>V. régulière</th>
    <th>V. singulière</th>
  </tr>
  <tr>
    <td>1</td>
    <td> $\mu_1$ </td>
    <td> $\mu +\alpha_1$ </td>
  </tr>
  <tr>
    <td>2</td>
    <td> $\mu_2$ </td>
    <td> $\mu +\alpha_2$ </td>
  </tr>
    <tr>
    <td> </td>
    <td>  </td>
    <td>   </td>
  </tr>
  </tr>
    <tr>
    <td> </td>
    <td>  </td>
    <td>   </td>
  </tr>
  </tr>
    <tr>
    <td> </td>
    <td>  </td>
    <td>   </td>
  </tr>
    <tr>
    <td>I</td>
    <td> $\mu_I$ </td>
    <td> $\mu +\alpha_I$ </td>
  </tr>
</table> 

--

<a class=care> Problème </a> : Version régulière mal définie. Le modèle dans cette version est dit <a style="font-weight:400;"> indéterminé</a>.


--
#### Exemple
Si $\mu_1 =10,\ \mu_2=12,$ dans la forme singulière peut correspondre à 

- $\mu =10,\ \alpha_1=0, \ \alpha_2=2,$
- ou $\mu =0,\ \alpha_1=10, \ \alpha_2=12,$
- ou $\mu =11,\ \alpha_1=-1, \ \alpha_2=1,$
- ou $\mu =15,\ \alpha_1=-5, \ \alpha_2=-3,$
- $\ldots$


--
<a class=care> Solution </a> : Choisir une contrainte. Par défaut dans R, $\alpha_1=0$. La référence est le comportement du groupe 1. 



---
template: model
## Version singulière du modèle du modèle M1 en intégrant la contrainte par défaut



$$\class{alea}{Y_{ik}} = \class{rouge}{\mu} + \class{rouge}{\alpha_{i}} + \class{alea}{E_{ik}}, \quad \class{alea}{E_{ik}}\overset{ind}{\sim}\mathcal{N}(0, \class{rouge}{\sigma^2}).$$

avec 
- $i=1,\ldots,I$ le numéro du groupe,
- $k= 1,\ldots, n_i$ le numéro de l'individu dans le groupe $i$, ($\sum_i n_i = n$ nombre total d'individus)
- $\class{rouge}{\mu}$ un comportement moyen de référence <a class=care> c'est celui du groupe 1</a>
- $\class{rouge}{\alpha_1}=0$  la contrainte choisie, $\alpha_1$ n'est plus un paramètre d'intérêt.
- $\class{rouge}{\alpha_i}, i\geq 2$ un effet différentiel du groupe $i$par rapport à la référence(i.e. le groupe 1)
- $\class{rouge}{\sigma^2}$ la variance commune à tous les groupes.


### Nombre de paramètres du modèle

- $I$ paramètres de moyenne $(\class{rouge}{\mu},  \class{rouge}{\alpha_2}, \ldots, \class{rouge}{\alpha_I})$,
- 1 paramètre de variance $\class{rouge}{\sigma^2}.$

---
template: model
## Version singulière du modèle du modèle M1 sur l'exemple 1  en intégrant la contrainte par défaut

$$\class{alea}{Y_{ik}} \overset{ind}{\sim}\mathcal{N}(\class{rouge}{\mu} + \class{rouge}{\alpha_i}, \class{rouge}{\sigma^2}),$$
avec 
- $I=3$ et  la convention $i=1$ pour la natation et $i=2$ pour le pilate et $i=3$ pour la pétanque.
- $k=1, \ldots, n_i$, avec $n_1=8,$  $n_2=8$ et $n_3=8$, 
- $\class{rouge}{\mu}$ la fréquence cardiaque moyenne de référence, c'est-à-dire, avec la contrainte par défaut de R la fréquence cardiaque des nageurs/nageuses. 
- $\class{rouge}{\alpha_1}$, l'effet différentiel de la pratique de la natation  par rapport à la référence (donc valant 0), $\class{rouge}{\alpha_2}$ l'effet différentiel de la pratique du pilate et $\class{rouge}{\alpha_3}$ l'effet différentiel de la pratique de la pétanque  par rapport à la référence.
- $\class{rouge}{\sigma^2}$ la variance commune à tous les groupes.




### Nombre de paramètres
- 4 paramètres de moyenne
- 1 paramètre de variance



---
name: parametre
# Etude des paramètres du modèle

---
template: parametre
## Quelques précisions de notations et de vocabulaires

- Les données observées (les valeurs prises par la variable $Y$ ) : $\bf{y}=(y_{11}, y_{12}, \ldots, y_{I n_I}).$ 

- En refaisant la même expérience, on obtiendrait d'autres valeurs (liées àaux choix d'individus différents par exemple, ou mesuré un autre jour, ...), on va noter $Y_{ik}$ la variable aléatoire qui décrit la loi des valeurs possibles pour l'individu k du groupe i.   

<br>
<a class=care> les minuscules notent des valeurs, les majuscules des variables aléatoires. </a>
<br>

--

Les paramètres du modèle  sont inconnus. Ils sont notés par des lettres grecques $\class{rouge}{\bf{\theta}}$, $\class{rouge}{\mu}, \class{rouge}{\alpha}, \dots$. 


On veut en donner une estimation à partir des données observées ( $\class{fixe}{\bf{y}}$). Les estimations des paramètres sont notées par les mêmes lettres décorées d'un chapeau $\class{fixe}{\bf{\hat{\theta}}}, \class{fixe}{\hat{\mu}}, \class{fixe}{\hat{\alpha}}, \dots$.  


L'estimateur d'un paramètre est la variable aléatoire correspondante. Il sera noté en majuscule avec une lettre latine. Par exemple, l'etimateur de $\class{rouge}{\theta}$ sera noté $\class{alea}{T}$, l'estimateur de $\class{rouge}{\mu}$ sera noté $\class{alea}{M}$ et l'estimateur de $\class{rouge}{\alpha_1}$ sera noté $\class{alea}{A_1}$.



---
template: parametre
## Estimation des paramètres du modèle version régulière

$$\class{alea}{Y_{ik}} = \class{rouge}{\mu_i} + \class{alea}{E_{ik}}, \quad \class{alea}{E_{ik}}\overset{ind}{\sim}\mathcal{N}(0,\class{rouge}{\sigma^2}).$$

### Estimation

$\class{rouge}{\mu_i}$ représente le comportement moyen de l'ensemble des individus du groupe $i$.  On peut l'estimer par $\class{fixe}{\hat{\mu}_i} = \frac{1}{n_i}\sum_{k=1}^{n_i} \class{fixe}{y_{ik}}= \class{fixe}{y_{i\bullet}}$

--

### Estimateur 

L'estimateur de $\class{rouge}{\mu_i}$ est donc défini par $\class{alea}{M_i}= \frac{1}{n_i}\sum_{k=1}^{n_i} \class{alea}{Y_{ik}},$  c'est une variable aléatoire


- de loi normale $\mathcal{N}$, 
--

- et espérance $\mathbb{E}(\class{alea}{M_i}) = \class{rouge}{\mu_i}.$ 
--
<a class=care> C'est un estimateur sans biais</a>
--

- de variance $\mathbb{V}(\class{alea}{M_i}) =  \frac{\class{rouge}{\sigma^2}}{n_i}$
--
<a class=care> la variance de l'estimateur diminue quand le nombre d'individus dans le groupe augmente.</a>
--

$$\class{alea}{M_i} \sim\mathcal{N}\left(\class{rouge}{\mu_i}, \frac{\class{rouge}{\sigma^2}}{n_i}\right).$$


---
template: parametre
## Estimation des paramètres du modèle version singulière avec la contrainte par défaut

$$\class{alea}{Y_{ik}} = \class{rouge}{\mu} + \class{rouge}{\alpha_i} + \class{alea}{E_{ik}}, \quad \class{alea}{E_{ik}}\overset{ind}{\sim}\mathcal{N}(0,\class{rouge}{\sigma^2}).$$

### Estimation

- $\class{rouge}{\mu}$ représente le comportement moyen du groupe 1 (groupe de référence) : $\class{fixe}{\hat{\mu}} =  \class{fixe}{y_{1\bullet}}$
--

- $\class{rouge}{\mu} + \class{rouge}{\alpha_i} = \class{rouge}{\mu_i}$, donc  $\class{rouge}{\alpha_i} = \class{rouge}{\mu_i} -\class{rouge}{\mu}$ ,représente l'effet différentiel du groupe i par rapport au groupe de référence.  $\class{fixe}{\hat{\alpha_i}} = \class{fixe}{y_{i\bullet}} -\class{fixe}{y_{1\bullet}}$

--

### Estimateur 

L'estimateur de $\class{alea}{\mu}$ est donc défini par $\class{alea}{M}= \class{alea}{Y_{1\bullet}} = \frac{1}{n_1}\sum_{k=1}^{n_1} \class{alea}{Y_{1k}}.$  

$$\class{alea}{M} \sim\mathcal{N}\left(\class{rouge}{\mu}, \frac{\class{rouge}{\sigma^2}}{n_1}\right).$$

--

L'estimateur de $\alpha_i$ est donc défini par $\class{alea}{A_i}=  \class{alea}{Y_{i\bullet}} -\class{alea}{Y_{1\bullet}}.$

$$\class{alea}{A_i} \sim\mathcal{N}\left(\class{rouge}{\alpha_i}, \class{rouge}{\sigma^2}\left(\frac{1}{n_i} + \frac{1}{n_1}\right) \right).$$


---
template: parametre
## Estimation des paramètres pour l'exemple 1.

### Ce qu'on doit trouver

$$\class{fixe}{\hat{\mu}} = \class{fixe}{y_{1\bullet}}=\frac{1}{8}\sum_{k=1}^{8} y_{1k}= \frac{y_{11} + y_{12} + \ldots + y_{18}}{8}$$
$$\quad \class{fixe}{\hat{\alpha}_2} =\class{fixe}{y_{2\bullet}}-\class{fixe}{y_{1\bullet}}=\frac{1}{8}\sum_{k=1}^{8} \class{fixe}{y_{2k}} - \frac{1}{8}\sum_{k=1}^{8} \class{fixe}{y_{1k}}, \quad \class{fixe}{\hat{\alpha}_3} =\class{fixe}{y_{3\bullet}}-\class{fixe}{y_{1\bullet}}=\frac{1}{8}\sum_{k=1}^{8} \class{fixe}{y_{3k}} - \frac{1}{8}\sum_{k=1}^{8} \class{fixe}{y_{1k}}$$

```{r estim_par1,  echo = TRUE, eval = TRUE}
freqdata %>% group_by(Activite) %>% summarise(m = mean(freqC), n= n())
```
```{r estim_par1_save, eval = TRUE}
resM1 <- freqdata %>% group_by(Activite) %>% summarise(m = mean(freqC), n= n())
```


--

$\class{fixe}{\hat{\mu}} =$ `r resM1$m[1]` , $\class{fixe}{\hat{\alpha}_2}=$ `r resM1$m[2] - resM1$m[1]` et $\class{fixe}{\hat{\alpha}_3}=$ `r resM1$m[3] - resM1$m[1]`. 


---
count: false
template: parametre
## Estimation des paramètres pour l'exemple 1.

### Ce qu'on doit trouver

$\class{fixe}{\hat{\mu}} =$ `r resM1$m[1]` et $\class{fixe}{\hat{\alpha}_2}=$ `r resM1$m[2] - resM1$m[1]`et $\class{fixe}{\hat{\alpha}_3}=$ `r resM1$m[3] - resM1$m[1]`.  

--


### Estimer avec R

```{r estim_par_lm, echo = TRUE, eval = TRUE}
M1 <- lm(freqC ~ Activite, data = freqdata)
summary(M1)$coefficients
```

---
count: false
template: parametre
## Estimation des paramètres pour l'exemple 1.

```{r estim_par_lm_2, echo = TRUE, eval = TRUE}
M1 <- lm(freqC ~ Activite, data = freqdata)
summary(M1)
```

```{r estim_par_lm_3, echo = FALSE, eval = TRUE}
sigma_hat <- summary(M1)$sigma
```

---
template: parametre
## Retour sur la méthode d'estimation - Somme des carrés résiduel (RSS)

Naturellement, on a choisi d'estimer  $\class{rouge}{\mu_i}$ par $\class{fixe}{y_{i\bullet}}.$ 

--

En fait, $\class{fixe}{\hat{\mu}_i}$ est choisi pour minimiser $\class{fixe}{RSS_{M_1, obs}}$, la somme observée des erreurs au carré  donnée par  

$$\class{fixe}{RSS_{M_1, obs}} = \sum_{i=1}^I \sum_{k=1}^{n_i} (\class{fixe}{y_{ik}} - \class{fixe}{\hat{\mu}_i})^2.$$ 
--

Le modèle d'analyse de la variance 
$$\class{alea}{Y_{ik}} =\class{rouge}{\mu_i} +\class{alea}{E_{ik}}.$$
Pour un nouvel individu $k_0$ dans le groupe $i$, le modèle prédit que sa fréquence cardiaque sera $\class{fixe}{\hat{y}_{ik_0}}=\class{fixe}{\hat{\mu}_i}$.

$\class{fixe}{RSS_{M_1,obs}}$ se réécrit dans un cadre général comme 

$$\class{fixe}{RSS_{M_1, obs}} = \sum_{i=1}^I \sum_{k=1}^{n_i} (\class{fixe}{y_{ik}} - \class{fixe}{\hat{y}_{ik}})^2.$$ 

$$\class{alea}{RSS_{M_1}} = \sum_{i=1}^I \sum_{k=1}^{n_i} (\class{alea}{Y_{ik}} - \class{alea}{\hat{Y}_{ik}})^2.$$ 



---
template: parametre

## Loi de RSS

$$\frac{\class{alea}{RSS}}{\class{rouge}{\sigma^2}} \sim \chi^2(n-I).$$

--
## Estimateur de la variance 

  $$\class{alea}{S^2} =\frac{1}{n-I} \class{alea}{RSS}, $$
est un <a class=care> estimateur sans bias de  $\class{rouge}{\sigma^2}$ </a> .

--

## Estimation de $\sigma^2$

$$\class{fixe}{\hat{\sigma}}^2 =\frac{1}{n-I} \class{fixe}{RSS_{obs}}.$$


---

```{r var_est}
freqdata %>%  group_by(Activite) %>% #BREAK
  mutate(yhat =  mean(freqC)) %>% #BREAK
  mutate( Ehat = freqC-yhat,Ehat_2 = Ehat^2) %>% #BREAK
  ungroup %>% summarise(RSSobs=sum(Ehat_2)) %>% as.numeric() -> RSSobs 
RSSobs #BREAK
sigma2_hat <- RSSobs / (nrow(freqdata) - 2)
sigma2_hat #BREAK
sigma_hat <- sqrt(sigma2_hat)
sigma_hat #BREAK
```



`r chunk_reveal("var_est", break_type = "user")`

---

template: parametre
## Estimation du paramètre de variance sur l'exemple 1

### On doit trouver

$\hat{\sigma}=$ `r sigma_hat`.


--

### Avec R


```{r recal_lm_fit_command, echo = TRUE}
M1 <- lm(freqC ~ Activite, data = freqdata)
```

--

```{r var_est_lm, echo = TRUE, eval = TRUE}
summary(M1)$sigma
```

---
count: false
template: parametre
## Estimation du paramètre de variance sur l'exemple 1

### On doit trouver

$\hat{\sigma}=$ `r sigma_hat`.



```{r var_est_lm2, echo = TRUE, eval = TRUE}
summary(M1)
```


---
template: parametre
## Visualisation graphique des paramètres estimés

```{r anova_visu_par}
freqdata %>% mutate(ord = 0) %>% ggplot() + xlab('freqC') + ylab('Density') + geom_point(aes(x=freqC, col = Activite, y = ord), alpha = 0.5) +  scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + #BREAK
  geom_vline(data=resM1, aes(xintercept = m, col = Activite)) + #BREAK
  stat_function(fun = dnorm, n = 101, args = list(mean = resM1$m[1], sd = sigma_hat ), col =  "#FF0000") +
  stat_function(fun = dnorm, n = 101, args = list(mean = resM1$m[2], sd = sigma_hat ), col =  "#00A08A") +
  stat_function(fun = dnorm, n = 101, args = list(mean = resM1$m[3], sd = sigma_hat ), col =  "#F2AD00") 
```

---

`r chunk_reveal("anova_visu_par", break_type = "user", display_type="output")`


---
template: pause

### Méfiez vous 

- vérifier les degrés de liberté et le nom des paramètres
- Si quelque chose cloche, vérifier la nature des variables
- On peut transformer une variable en facteur à l'aide de la fonction `as.factor`.

---
name: modcomp
# Décider entre M0 et M1

--

**Test du modèle complet**


--

## Rappel exemple fréquence cardiaque (exemple 1)

On a mesuré la fréquence cardiaque de 8 nageurs/nageuses, 8 pratiquant.e.s de pîlate et 8 pratiquant.e.s de pétanque



```{r freqdata2, ref.label='freqdata', eval = TRUE, warning = FALSE, results ='markup'}
```


--
<p class="question"> Y a -t-il un lien entre fréquence cardiaque et activité sportive ?</p>

---
template: modcomp
## Rappel exemple fréquence cardiaque (exemple 1)


<p class="question"> Les hommes et les femmes ont-ils la même fréquence cardiaque au repos ?</p>


Autrement dit


```{r freqdata_graphia_anova, eval = TRUE, warning = FALSE, results ='markup'}
freq_p_M <- ggplot(data = freqdata) + geom_point(aes(x=freqC, y =0, col = Activite), alpha = 0.5)

freq_p_M1 <- freq_p_M + 
  stat_function(fun = dnorm, n = 101, args = list(mean = resM1$m[1], sd = sigma_hat ), col =  "#FF0000") +
  stat_function(fun = dnorm, n = 101, args = list(mean = resM1$m[2], sd = sigma_hat ), col =  "#00A08A") +
  stat_function(fun = dnorm, n = 101, args = list(mean = resM1$m[3], sd = sigma_hat ), col =  "#F2AD00") +
  geom_vline(aes(xintercept = resM1$m[1] ), col =  "#FF0000") +
  geom_vline(aes(xintercept = resM1$m[2] ), col =  "#00A08A")  +
  geom_vline(aes(xintercept = resM1$m[3] ), col =  "#F2AD00") 
M0 <- lm(freqC~1, data = freqdata)
freq_p_M0 <- freq_p_M +   stat_function(fun = dnorm, n = 101, args = list(mean = coef(M0), sd = summary(M0)$sigma ), col =  "#FF0000") +
 stat_function(fun = dnorm, n = 101, args = list(mean = coef(M0), sd = summary(M0)$sigma ),  col =  "#00A08A") +
  geom_vline(aes(xintercept =  coef(M0)), col= "#FF0000") +
  geom_vline(aes(xintercept =  coef(M0) ), col =  "#00A08A")  +
  geom_vline(aes(xintercept =  coef(M0) ), col =  "#F2AD00")  + theme(legend.position =  'bottom' ) 
  
ggpubr::ggarrange(freq_p_M1, freq_p_M0, common.legend = TRUE)
```

---
template: modcomp

```{r rappel_anova_versiongraphique_save, ref.label='anova_versiongraphique_save', eval = TRUE}
```

---
template: modcomp
## Test de l'existence d'un effet


<p class="question"> Le comportement moyen de la variable $Y$ est il différent selon les différentes modalités de la variable explicative ?</p>

--

Deux modèles possibles
$$M1 : Y_{ik} = \mu  + \alpha_i + E_{ik},\quad  M0: Y_{ik} = \mu  + E_{ik}$$

<p class="question"> Le modèle M1 est-il plus pertinent que le modèle M0?</p>


---
template: modcomp
## Mesurer la variabilité expliquée par le modèle M1

--

### Variabilité totale dans les données

$$RSS_{0, obs} = \sum_{i=1}^{I} \sum_{k=1}^{n_i} (y_{ik} - \bar{y})^2 = \sum_{i=1}^{I} \sum_{k=1}^{n_i} (y_{ik} - \hat{y}_{ik}^{(0)})^2.$$ 
--

### Variabilité résiduelle dans le modèle M1

$$RSS_{1, obs} = \sum_{i=1}^{I} \sum_{k=1}^{n_i}  ( y_{ik} - (\hat{\mu} +\hat{\alpha}_i))^2 = \sum_{i=1}^{I} \sum_{k=1}^{n_i}  ( y_{ik} - \hat{y}_{ik}^{(1)})^2.$$ 
--

### Variabilité expliquée par le modèle M1

$$SCM = SS_{M1,obs} =  RSS_{0, obs} - RSS_{1, obs}.$$ 
C'est la quantité de variabilité expliquée par les différence entre les I populations.

--

<p class=care> Si la variabilité expliquée par le modèle $M1$ est grande, on gagne à considérer des ppopulations différentes <p>

On a mis en évidence des différences entre les populations.


---
template: modcomp
## Calcul de RSS sur l'exemple 1

A la main :



```{r rss}
freqdata %>% group_by(Activite) %>% 
  mutate(m= mean(freqC)) %>% #BREAK
  mutate( Ehat = freqC - m) %>% #BREAK 
  mutate( E2hat = Ehat^2) %>% #BREAK
  ungroup() %>% #BREAK
  summarise(RSSM1 =sum(E2hat)) %>% as.numeric()-> #BREAK
  RSSM1 #BREAK
freqdata %>%  mutate(m= mean(freqC)) %>% #BREAK
  mutate( Ehat = freqC - m) %>% #BREAK
  mutate( E2hat = Ehat^2) %>% #BREAK
  summarise(RSSM1 =sum(E2hat)) %>% as.numeric()-> #BREAK
  RSSM0
SSM <- RSSM0 - RSSM1 #BREAK
SSM #BREAK
```

---


`r chunk_reveal("rss", break_type = "user")`


```{r rss_cache,  eval = TRUE}
freqdata %>% group_by(Activite) %>%
  mutate(m= mean(freqC)) %>% 
  mutate( Ehat = freqC - m) %>% 
  mutate( E2hat = Ehat^2) %>% 
  ungroup() %>% 
  summarise(RSSM1 =sum(E2hat)) -> 
  RSSM1
freqdata %>%  mutate(m= mean(freqC)) %>% 
  mutate( Ehat = freqC - m) %>% 
  mutate( E2hat = Ehat^2) %>% 
  summarise(RSSM1 =sum(E2hat)) -> 
  RSSM0
SSM <- as.numeric(RSSM0 - RSSM1)
SSM
```

---
template: modcomp
## Calcul de RSS sur l'exemple 1


```{r SCM,  echo = TRUE, eval = TRUE, highlight = 1:2}
M1 <- lm(freqC ~ Activite, data= freqdata)
M0 <- lm(freqC ~ 1, data= freqdata)
anova(M0, M1)
```



---
template: modcomp
## Quand décider si $SS_{M1, obs}$ est grande ?  


--
C'est le rôle du test statistique.

--

Idée de démarche:

- Décrire quelle gamme de valeurs pourrait prendre SSM dans le cas où il n'y pas de différence entre les groupes 
- Comparer avec ce qu'on constate sur nos données
- 
    - Si c'est comparable, pas de raison de penser qu'il y a des différences entre les groupes,
    - Si c'est surprenant, les groupes sont vraisemblablement différentes.

--

On veut décrire comment varie $SS_{M1, obs}$ dans la situation où il n"y a pas de différence entre les groupes.

On travaille donc sous l'hypothèse 
$$H_0 =\left \lbrace \mbox{Pas de différence entre les groupes }\right\rbrace$$

--

$$H_0 =\left \lbrace  \mbox{pour tout }i, \alpha_i =0  \right\rbrace$$

--

$$H_0 =\left \lbrace  M1 \mbox{ est équivalent à } M0 \right\rbrace.$$

---
template: modcomp
## Hypothèses du test

On va donc opposer une hypothèse de travail $H_0$ contre une hypothèse alternative $H_1$. $H_0$ peut donc prendre différentes formes:


$$\begin{align} 
H_0 & =\left \lbrace \mbox{Pas de différence entre les groupes }\right\rbrace\\
    & =\left \lbrace  \mbox{pour tout }i, \alpha_i =0  \right\rbrace\\
    & =\left \lbrace  M1 \mbox{ est équivalent à } M0 \right\rbrace.
\end{align}$$

$H_1$ prend les formes équivalentes suivantes

$$\begin{align} 
H_1 & =\left \lbrace \mbox{Au moins 1 groupe est différent des autres}\right\rbrace\\
    & =\left \lbrace  \mbox{Il existe un }i, \alpha_i  \ne 0  \right\rbrace\\
    & =\left \lbrace  M1 \mbox{ est préférable à } M0 \right\rbrace.
\end{align}$$

---
template: modcomp
## Loi de la statistique de test sous $H_0$


Il faut être capable de décrire quelles sont les valeurs possibles de $SS_{M1, obs}$, pour ceci il faut connaitre la loi de la variable aléatoire $SS_{M1}$.

--

On peut montrer que sous $H_0$,  


<p class=question> 
Sous $H_0$, 
$$F= \frac{\frac{SS_{M1}}{I-1}}{\frac{RSS}{n-I}} \underset{H_0}{\sim}\mathcal{F}(I-1, n-I)$$  
</p>


--

Intuitivement le numérateur de $F$ mesure la force d'un signal, le dénominateur un niveau de bruit. Plus la valeur de $F$ est grande, plus il est raisonnable de penser que le signal capturé par le modèle est fort et donc révélateur d'un véritable effet de la variable explicative.

---
template: modcomp
## Loi de la statistique de test sous $H_0$ - graphiquement

Sous $H_0$ la loi de distribution de $F$ est 

```{r p_value, eval = TRUE}
tibble(x = seq(0, 10, length.out = 2001)) %>% 
  mutate(y = df(x, df1 = 4, df= 38)) -> chi_dta
Fobs <- 1
chi_dta %>% filter(x> Fobs) %>% add_row(x=100,y = 0) %>%  add_row(x=Fobs, y =0)  %>% 
  add_row(x=Fobs, y =df(Fobs, df1 = 4, df= 38)) %>% arrange(x,y)  -> chi_dta_poly
ggplot(data  = chi_dta) + xlab('y') + ylab('density') + geom_line(aes(x=x, y=y))
```


```{r pvalue_graphique}
ggplot(data  = chi_dta) + xlab('y') + 
  ggtitle("Une valeur de la statistique peu surprenante") + ylab('density') + geom_line(aes(x=x, y=y)) + #BREAK
  annotate("text", x = Fobs- 0.5, y = 0.05, label = "Fobs", col = 'red')+  geom_vline(aes(xintercept = Fobs), col = 'red') 

```


```{r pvalue_graphique_2}
ggplot(data  = chi_dta) + xlab('y') + 
  ggtitle("Une valeur de la statistique peu surprenante") + ylab('density') + geom_line(aes(x=x, y=y)) + #BREAK
  annotate("text", x = 3, y = 0.05, label = "Fobs", col = 'red')+  geom_vline(aes(xintercept = Fobs), col = 'red') 

```

---

`r chunk_reveal("pvalue_graphique", break_type = "user", display_type="output")`


---

`r chunk_reveal("pvalue_graphique_2", break_type = "user", display_type="output")`

---
template: modcomp

## Mesurer le caractère surprenant : Proabilité critique

```{r pvalue_graphique_3, eval = TRUE}
ggplot(data  = chi_dta) + xlab('y') + 
  ggtitle("Une valeur de la statistique peu surprenante") + ylab('density') + geom_line(aes(x=x, y=y)) + #BREAK
  annotate("text", x = 3, y = 0.05, label = "Fobs", col = 'red')+  geom_vline(aes(xintercept = Fobs), col = 'red') + #BREAK
  geom_polygon(data = chi_dta_poly,  aes(x=x, y= y), alpha = 0.3) + xlim(c(0, max(chi_dta$x))) 

```

--
La probabilité critique ( p-value en anglais) est définie par 

$$ \mathbb{P}(F> F_{obs} \vert H_0)$$

--

Intuitivement c'est la probabilité d'observer Fobs ou des valeurs encore plus extrèmes sous $H_0$.

--

On va rejeter $H_0$ lorsque la probabilité critique est faible (typiquement inférieure à 5%). La valeur de la statistique de test observée est peu compatible avec l'hypothèse $H_0$. On ne croit pas à $H_0$.


---
template: modcomp
## Déclinaison sur l'exemple Fréquence cardiaque


```{r anova_FC_F, echo = TRUE, eval =TRUE}

anova(M0,M1)

```

--


```{r pvalue_graphique-ex_FC, eval = TRUE}
Fobs <- anova(M0,M1)$F[2]
chi_dta %>% filter(x> Fobs) %>% add_row(x=100,y = 0) %>%  add_row(x=Fobs, y =0)  %>% 
  add_row(x=Fobs, y =df(Fobs, df1 = 4, df= 38)) %>% arrange(x,y)  -> chi_dta_poly
ggplot(data  = chi_dta) + xlab('y') + ylab('density') + geom_line(aes(x=x, y=y)) + 
  annotate("text", x = Fobs- 0.5, y = 0.05, label = "Fobs", col = 'red')+  geom_vline(aes(xintercept = Fobs), col = 'red') +
  geom_polygon(data = chi_dta_poly,  aes(x=x, y= y), alpha = 0.3) + xlim(c(0, max(chi_dta$x))) 
```
---
template: modcomp
## Sur l'exemple chauve souris


### Pouvez vous répondre à la question 

<a class=question> Y a-t-il un effet du régime alimentaire sur le volume de la partie auditive du cerveau ? </a>



---
name: test_param
# Comparer les modalités


---
template: test_param
## Réflexion sur le sens de ce test

On souhaite comparer les différentes modalités : et répondre aux questions 

* La fréquence cardiaque des nageurs est-elle différente de la fréquence cardiaque des pratiquants de yoga ?
* La fréquence cardiaque des nageurs est-elle différente de la fréquence cardiaque des joueurs de pétanque ? 
* La fréquence cardiaque des pratiquants de yoga est-elle différente de la fréquence cardiaque des joueurs de pétanque ? 

--

Comment faire ?

-- 

Tester 

$$H_0 : \left\lbrace (\mu+\alpha_i) = (\mu + \alpha_j) \right\rbrace = \left\lbrace\alpha_i =  \alpha_j \right\rbrace $$
contre 
$$H_1 : \left \lbrace(\mu+\alpha_i \ne \mu + \alpha_j) \right\rbrace = \left\lbrace\alpha_i \ne  \alpha_j \right\rbrace $$
---
template: test_param
## Mise en place du test de comparaison des modalités

Sous $H_0$,

$$T = \frac{Y_{i,\bullet} -Y_{j,\bullet}}{ \hat{\sigma} \sqrt{\frac{1}{n_i} + \frac{1}{n_j}}} \sim \mathcal{T}(DDL_{res})$$

où $\mathcal{T}(DDL_{res})$ désigne la loi de Student à $DDL_{res}$ degrés de liberté. 
--

### Définition de la p-value


```{r fig_pvalue_stu_ex}
tobs <- 1 
df1 <- 20
tibble::tibble( y = seq( -4, 4, length.out = 1001)) %>% 
  mutate( tj = dt(y, df = df1), nj= dnorm(y, mean = 0, sd = 1) ) -> stat_test
stat_test %>% filter((y) > abs(tobs)  ) %>% add_row(y = abs(tobs), tj = 0) %>% add_row(y = abs(tobs), tj = dt(abs(tobs), df = df1)) %>% arrange(y,tj) -> poly_droit
stat_test %>% filter((y) < -abs(tobs)  ) %>% add_row(y = -abs(tobs), tj = 0) %>% add_row(y = -abs(tobs), tj = dt(-abs(tobs), df = df1)) %>% arrange(-y,tj, decreasing = TRUE) -> poly_gauche
ggplot(data = stat_test) + xlim(-4,4) +
  geom_point(aes(x=tobs, y = 0), col = 'red') + #BREAK
  annotate("text", x = tobs - 0.3, y = 0.02, label = "tobs", col = 'red') + #BREAK
  geom_line(aes(x= y, y = tj)) + #BREAK
  geom_vline(aes(xintercept = abs(tobs)), col = 'red') + #BREAK
  geom_polygon(data = poly_droit, aes(x=y, y = tj), alpha = 0.5) + #BREAK
  geom_point(aes(x=-tobs, y = 0), col = 'red') + #BREAK
  annotate("text", x = - tobs + 0.3, y = 0.02, label = "- tobs", col = 'red') + #BREAK
  geom_vline(aes(xintercept = - abs(tobs)), col = 'red') + #BREAK
  geom_polygon(data = poly_gauche, aes(x=y, y = tj), alpha = 0.5) 

```

---
`r chunk_reveal("fig_pvalue_stu_ex", break_type = "user", display_type="output")`


---
template: test_param

## Déclinaison sur les exemples

## Comparaison des pratiques sportives

```{r test_alpha1}
M1 <- lm(freqC~Activite, data = freqdata)
library(emmeans)
FC_mean <- emmeans(object = M1, specs = ~Activite)
FC_mean
pairs(FC_mean,  adjust = "bonf")
plot(FC_mean)
```
---

`r chunk_reveal("test_alpha1", break_type = "user", display_type="output")`

---

- $\hat{\sigma}=$ `r round(summary(M1)$sigma,3)`.
- $\sqrt{c_j}\hat{\sigma}=$ `r round(summary(M1)$coefficients[1,2],3)`,
- $t_{j,obs}=$ `r round(summary(M1)$coefficients[1,3],3)`,
- p-value= `r round(summary(M1)$coefficients[1,4], 6)`,

--

```{r summary_alpha1, eval =TRUE, echo = TRUE}
summary(M1)
```


---
# Démarche complète d'analyse à partir de l'exemple des chauves souris

Une question initiale :  Le volume auditif dépend il de régime alimentaire. 
- Représenter les données en fonction des questions qu'on se pose.
- Ecrire le modèle 
- Traduire la question en 1 ou plusieurs tests statistiques
- Apporter une réponse concrète

  
---
# Bilan sur le modèle d'analyse de la variance à 1 facteur


### But 
Etudier le lien entre une variable quantitative (la fréquence cardiaque) et un facteur (le Activite).

## Le modèle 
$$Y_{ik} = \mu + \alpha_i + E_{ik}$$
avec $\mu$ le comportement de référence et $\alpha_i$ l'effet différentiel du groupe $i$  par rapport à la référence. 

La référence est définie par la contrainte choisie. R par défaut choisit la contrainte $\alpha_1=0$, ce qui place le groupe 1 comme groupe de référence.

## Tests

* Pour comparer des modèles ( pour tester un potentiel effet du facteur),

* Comparer les modalités (trouver quelles sont les modalités différentes les unes des autres)

## Conclusion concrète




---

```{r ggplot_back, echo = FALSE, eval = TRUE}
ggplot <- function(...) ggplot2::ggplot(...) 
```



