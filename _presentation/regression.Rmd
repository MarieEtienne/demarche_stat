---
title: Régression linéaire 
subtitle: multiple
author: Marie-Pierre Etienne
date: '2021/11/19 (updated: `r Sys.Date()`)'
institute: marie-pierre.etienne@agrocampus-ouest.fr
csl: ../courses_tools/resources/apa-no-doi-no-issue.csl
output:
   xaringan::moon_reader:
    css: ['metropolis',  'mpe_pres.css']
    lib_dir: libs
    nature:
      ratio: 16:10
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: '../courses_tools/resources/collapseoutput.js'
---
name: intro

<!-- F1D763 -->
<!-- F7A913 -->
<!-- C94326 -->
<!-- 1F908E -->
<!-- 33658A -->


```{r setup, include = FALSE,  eval = TRUE}
library('RefManageR')
source("../courses_tools/resources/knitr_setup.R")

common_img_dir <- file.path(main_dir,'courses_tools','resources', 'common_figs')
course_img_dir <- file.path(main_dir,'resources', 'figs')
BibOptions(check.entries = FALSE,
           bib.style = "authoryear",
           cite.style = "authoryear",
           style = "markdown",
           hyperlink = TRUE,
           max.names = 3,
           longnamesfirst= FALSE, 
           dashed = TRUE)
#myBib <- ReadBib('biblio_soutenance.bib', check = FALSE)
```

```{r xaringan-fit-screen, echo=FALSE}
xaringanExtra::use_fit_screen()
```


# Introduction

--
## Etude de la pollution au SO2

On a mesuré pour 41 villes américaines, la pollution au SO2 ainsi que la population dans la ville

```{r datapackage, eval = TRUE, echo = FALSE, warning = FALSE}
ggplot <- function(...) ggplot2::ggplot(...) + scale_fill_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) + scale_color_manual(values = wesanderson::wes_palette(name = "Darjeeling1")) 
#remotes::install_github('MarieEtienne/coursesdata', force = TRUE)
```

```{r usdata_load, eval = TRUE, echo = c(1,2), warning = FALSE}
library(coursesdata) #remotes::install_github('MarieEtienne/coursesdata')
data(usdata)
```

---
name: reg_multiple
# Le modèle de régression multiple

--

## Présentation du problème
.pull-left[
Dans l'exemple de la pollution en SO2 des villes, plusieurs variables sont potentiellement liées à la pollution en SO2


- temp : Average temperature in Fahrenheit
- manuf : No. of companies employing more than 20 employees
- pop : Population in thousands
- wind : Average annual wind speed in miles/hour
- precip : annual precipitation height in inches
- days : No. of days of precipitation

]

--

.pull-right[

```{r show_data, eval = TRUE}
usdata %>% as_tibble() %>% print(n=5)
```

]

--
.center[
<a class=question> Quelles sont les variables liées à la pollution en SO2 ? </a>
]



---
template: reg_multiple

## Le modèle de régression multiple 

$$\class{alea}{Y_{k}} = \class{rouge}{\beta_0} +\class{rouge}{\beta_1} x_{k,1}  + \class{rouge}{\beta_2} x_{k,2} + \ldots +  \class{rouge}{\beta_p} x_{k,p}  +  \class{alea}{E_{k}},\quad \class{alea}{E_{k}}\overset{ind}{\sim}\mathcal{N}(0, \class{rouge}{\sigma^2}),$$
avec 
- $x_{k,l}$ la valeur de la variable explicative $l$ pour l'observation $k$, 
- $k=1,\ldots,n$ le numéro d'individu, $n$ le nombre total d'individus,
- $\class{rouge}{\beta_0}$ l'ordonnée à l'origine, 
- $\class{rouge}{\beta_l}$ l'effet de la variable $x{,l}$ sur la variable à expliquer,
- $\class{rouge}{\sigma^2}$ la variance.

--

### Nombre de paramètres du modèle

- $p+1$ paramètres de moyenne  $(\class{rouge}{\beta_0}, \class{rouge}{\beta_1}, \ldots, \class{rouge}{\beta_p})$; 
- 1 paramètre de variance $\class{rouge}{\sigma^2}$

---
name: modcomp
# Test du modèle complet

--

## Pollution 

<p class="question"> La pollution en SO2 dans les villes américaines est elles liées à l'une au moins des variables caractérisiques des villes ?</p>


--

On va à la pêche ....

---
template: modcomp
## Sous forme de comparaison de modèle



```{r reg_versiongraphique_prep, eval = TRUE, echo = FALSE}
set.seed(222)
n <- 20
x <- round(rnorm(n, mean= 10, sd = 2),2)
beta0 <- 1
beta1 <- 0.5
sigma <- 1
fake_dta <- tibble(x= x, y = rnorm(n, mean = beta0 + beta1*x, sd =sigma))  

x0 <-  x[9]
y0 <- fake_dta$y[9]
norm_dta <- tibble::tibble(y = rnorm(1000, mean=beta0 + beta1*x0, sd= sigma), x= x0 + dnorm(x = y- beta0 - beta1*x0, mean= 0,  sd=0.5))

norm_dta0 <- tibble::tibble(y = rnorm(1000, mean=mean(fake_dta$y), sd= sigma), x= x0 + dnorm(x = y - mean(fake_dta$y), mean= 0,  sd=0.5))


pM0<- ggplot(data=fake_dta) + 
  ylab('y') + xlim(range(fake_dta$x)) +ylim(range(fake_dta$y)) +
  ggtitle('Modèle nul') +
  geom_abline(slope = 0, intercept = mean(fake_dta$y)) + #BREAK
  geom_point(x=x0, y = mean(fake_dta$y), col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta0, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
pMcomp <- ggplot(data=fake_dta) + 
  ylab('y') + xlim(range(fake_dta$x)) +ylim(range(fake_dta$y)) +
  ggtitle('Modèle Mcomp') +
  geom_abline(slope = beta1, intercept = beta0) + #BREAK
  geom_point(x=x0, y=beta0+beta1*x0, col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
ggpubr::ggarrange(pMcomp, pM0, nrow = 1, common.legend = TRUE)

```

--

Sauf que le modèle complet est bien plus complet ....

--
<p class="question"> Le modèle Mcomp est il plus pertinent que le modèle M0 ?</p>



---
template: modcomp
## Hypothèses du test

On va donc opposer une hypothèse de travail $H_0$ contre une hypothèse alternative $H_1$. $H_0$ peut donc prendre différentes formes:


$$\begin{align} 
H_0 & =\left \lbrace \mbox{Auncune variable n'est liée à la pollution en SO2}\right\rbrace\\
    & =\left \lbrace  \mbox{pour tout }1\leq l\leq p, \class{rouge}{\beta_l} =0   \right\rbrace\\
    & =\left \lbrace  M_{comp} \mbox{ est équivalent à } M0 \right\rbrace.
\end{align}$$


$H_1$ prend les formes équivalentes suivantes

$$\begin{align} 
H_1 & =\left \lbrace \mbox{Au moins 1 variable est liée à la pollution en SO2}\right\rbrace\\
    & =\left \lbrace  \mbox{Il existe un }l,\  1\leq l\leq p, \class{rouge}{\beta_l} \ne 0  \right\rbrace\\
    & =\left \lbrace  M_{comp} \mbox{ est préférable à } M0 \right\rbrace.
\end{align}$$

--

Sous $H_0$, 

$$F= \frac{ \frac{\class{alea}{RSS_0 - RSS}}{p} }{\frac{\class{alea}{RSS}}{n-(p+1)}}  \underset{H_0}{\sim}\mathcal{F}(p, n-(p+1))$$  

---
template: modcomp
## Loi de la statistique de test sous $H_0$ - graphiquement

Sous $H_0$ la loi de distribution de $F$ est 

```{r p_value, eval = TRUE}
tibble(x = seq(0, 10, length.out = 2001)) %>% 
  mutate(y = df(x, df1 = 4, df= 38)) -> chi_dta
Fobs <- 1
chi_dta %>% filter(x> Fobs) %>% add_row(x=100,y = 0) %>%  add_row(x=Fobs, y =0)  %>% 
  add_row(x=Fobs, y =df(Fobs, df1 = 4, df= 38)) %>% arrange(x,y)  -> chi_dta_poly
```


```{r pvalue_graphique}
ggplot(data  = chi_dta) + xlab('y') + ylab('density') + geom_line(aes(x=x, y=y)) + #BREAK
  annotate("text", x = Fobs- 0.5, y = 0.05, label = "Fobs", col = 'red')+  geom_vline(aes(xintercept = Fobs), col = 'red') + #BREAK
  geom_polygon(data = chi_dta_poly,  aes(x=x, y= y), alpha = 0.3) + xlim(c(0, max(chi_dta$x))) 

```

---

`r chunk_reveal("pvalue_graphique", break_type = "user", display_type="output")`

---
name: test_variable
# Test de l'effet des variables

---
template: test_variable

## Test sur les paramètres

Tester la nullité du paramètre $\class{rouge}{\beta_l}$ revient à tester si la variable $x_{.,l}$ et la variable $Y$ sont liées.


--

Ce test est similaire  au test de comparaison entre le modèle complet et le modèle complet privé de la variable $x_{,l}$.


$$\begin{align} 
H_0 & =\left \lbrace \mbox{Dans le modèle complet la variable } l \mbox{ n'a pas d'influence}\right\rbrace\\
    & =\left \lbrace  \mbox{Dans le modèle complet la variable } \class{rouge}{\beta_l=0} \right\rbrace\\
    & =\left \lbrace  M_{comp} \mbox{ est équivalent à } M_{-l} \right\rbrace,
\end{align}$$

avec 
$$M_{-l}: \class{alea}{Y_k} = \class{rouge}{\beta_0} + \class{rouge}{\beta_1} x_{k,1} + \ldots + \class{rouge}{\beta_{l-1}} x_{k,l-1} + \class{rouge}{\beta_{l+1}} x_{k,l+1} + \ldots + \class{rouge}{\beta_{p}} x_{k,p} + \class{alea}{E_{k}}$$

---
count: false
template: test_variable

## Equivalence des tests sur l'exemple de la pollution : effet de la population
.pull-left[

```{r car, echo=FALSE, eval=TRUE}
library(car)
```

```{r pol_mult, eval = TRUE, echo = TRUE}
Mcomp <- lm(SO2 ~ temp + manuf + pop +wind + precip + days, data = usdata)
summary(Mcomp)$coefficients
```
]
--
.pull-right[
### Lien entre les statistiques  de tests

```{r stu2, eval = TRUE, echo =TRUE}
Mcomp_l <- lm(SO2 ~  temp + manuf +  wind + precip + days, data = usdata) 
anova(Mcomp_l, Mcomp)
```
]
---
template: test_variable
## Vigilance sur l'interprétation des tests et des estimations


```{r test_inter, eval =TRUE}
summary(Mcomp)$coefficients
```

--
```{r ggpairs, eval = TRUE}
GGally::ggpairs(usdata, columns = 2:8)
```


---
name: ajust
# Ajustement et choix de modèles



```{r surajust_simulation, eval = TRUE, echo = FALSE}
set.seed(123)
beta0 <- 100
beta1 <- 2
beta2 <- 1

n <- 20
imax <-9
x <- round(rnorm(n, mean=0, sd = 5),1)
y <- rnorm(n, mean= beta0+beta1*x - beta2 * x^2, sd = 16)
dta <- tibble(x1=x, y=y, x2 =x^2, x3 = x^3, x4 = x^4 , x5 =x^5, x6 =x^6, x7= x^7, x8 = x^8, x9 =x^9, x10= x^10, x11 = x^{11} ) 

new_dta <- tibble(x=seq(min(x), max(x), length.out=1000),x1=x,  x2=x^2, x3 =x^3, x4 =x^4, x5 = x^5, x6 =x^6, x7= x^7, x8 = x^8, x9 =x^9, x10= x^10, x11 = x^{11} ) 

surajust_list <- lapply(1:imax, function(i){
  if(i==1)
    f1 <-  as.formula('y ~1')
  else
    f1 <-  as.formula(paste0('y ~  ',paste0( paste0('x', 1:(i-1), collapse = ' + '))))
  M <- lm(f1, data=dta)
  p <- new_dta%>% 
  mutate(y=as.numeric(predict(M, newdata=new_dta)))%>% 
  ggplot() +geom_line(aes(x=x, y=y), col =  "#33658A")+ geom_point(data=dta, aes(x=x, y=y))+
  ylim(c(-55,150)) + labs(x='', y='') +ggtitle(paste0('Ajustement avec ', i-1, ' variable(s)'))
  R2 <- summary(M)$r.squared
  return(list(p=p, R2=R2, AIC = AIC(M), Model=paste0('M',i-1)))
})
```


## Un critère pour mesurer l'ajustement du modèle

--

### Le coefficient de détermination $R^2$ pour un modèle

$$\class{fixe}{R^2(M)}= 1 -\frac{\class{fixe}{RSS_M}}{\class{fixe}{RSS_0}}$$
représente la proportion de variabilité totale capturée par le modèle.
--

### Les limites de $R^2$ pour la sélection

.pull-left[
```{r R2_table, echo = FALSE, eval = TRUE}
tibble(Model = paste0('M', (1:imax)-1), R2= unlist(lapply(surajust_list, function(l){l$R2}))) %>% 
  kableExtra::kable(digits=4, format = "html", escape = FALSE) 
  
```
]

--

 .pull-right[
```{r ajust_git, eval = TRUE, message = FALSE}
  gif <-function(){ 
      lapply(surajust_list, function(i) {
        print(i$p)
      })
    }
    library(animation)
     ok <- saveGIF(gif(), interval = 2, movie.name="Ajustement.gif")
```
 
  <IMG SRC="Ajustement.gif">
 
 ]

---
template: ajust


### Le coefficient de détermination $R^2$

$$\class{fixe}{R^2(M)}= 1 -\frac{\class{fixe}{RSS_M}}{\class{fixe}{RSS_0}}$$
représente la proportion de variabilité totale capturée par le modèle.

### Le critère Akaike (AIC)

Il utilise la vraisemblance $^1$  et lui ajoute une pénalité pour compenser le nombre de paramètre et éviter le surajustement.

Il est défini de manière générale pour les modèles statistiques mais dans le cas du modèle linéaire, il est donné par 


$$ AIC(M) = p +  n \class{orange}{\ln{\frac{RSS}{n-(p+1))}}} + n + 3 + n\ln{2\pi} $$

$$ AIC(M) = p +  n \class{orange}{\ln{\hat{\sigma}^2_M}}  \class{clair}{ + n + 3 + n\ln{2\pi}} $$
.care[On va préférer le modèle avec l'AIC le plus petit]

.footnote[1: vraisemblance : une fonction qui mesure justement l'ajustement du modèle aux données]
---

name: ajust
# Ajustement et choix de modèles

## Comparaison AIC et $R^2$

--
.pull-left[
```{r R2_AIC_table, echo = FALSE, eval = TRUE}
tibble(Model = paste0('M', (1:imax)-1), R2= unlist(lapply(surajust_list, function(l){l$R2})),
       AIC = unlist(lapply(surajust_list, function(l){l$AIC}))) %>% 
  kableExtra::kable(digits=4, format = "html", escape = FALSE) 
  
```
]



 .pull-right[

  <IMG SRC="Ajustement.gif">
 
 ]


Utilisé en TD pour choisir un modèle avec un bon compromis ajustement et parcimonie (petit nombre de paramètres).

---

name: prediction
# Prediction

--

Il est fréquent d'utiliser un modèle de régression pour prédire. 

## Cas de la régression multiple

### Prédiction de la valeur moyenne pour des variables explicatives  $(x_1, \ldots, x_p)$ particulières

--

$$\hat{Y}_k = \class{fixe}{\hat{\beta}_0} +\class{fixe}{\hat{\beta}_1} x_{k,1}+ \ldots + \class{fixe}{\hat{\beta}_p} x_{k,p}$$



---
# Ce qu'il faut absolument savoir pour les TDs

- savoir reconnaître une situtation de régression multiple
--

  * On cherche à comprendre le lien entre une variable d'intérêt $Y$ et des variables potentiellement explicatives toutes quantitatives.
  
--
- savoir écrire le modèle de régression multiple

--
- Tester l'existence de l'effet d'au moins une des variables explicatives candidates

--
- Tester l'existence de l'effet d'une variable explicative particulière

--
- Pourquoi il faut se méfier du $R^2$

--
- Ce que signifie prédire en utilisant le modèle et comment le faire





```{r ggplot_back, echo = FALSE, eval = TRUE}
ggplot <- function(...) ggplot2::ggplot(...) 
```

